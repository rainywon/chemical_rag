import time
from typing import List, Dict, Optional, Tuple
import fitz
import cv2
import numpy as np
from langchain_core.documents import Document
from paddleocr import PaddleOCR
from multiprocessing import Pool, cpu_count
import os
import logging
import torch  # æ·»åŠ torchå¯¼å…¥ä»¥æ£€æµ‹GPU
import paddle  # ç›´æ¥å¯¼å…¥paddleæ£€æŸ¥ç¯å¢ƒ
from pathlib import Path
from config import Config
import json
from datetime import datetime

"""
ä½¿ç”¨ç¤ºä¾‹:

# åŸºç¡€ä½¿ç”¨æ–¹å¼ï¼ˆä»ConfigåŠ è½½å‚æ•°ï¼‰
from config import Config
config = Config()
processor = PDFProcessor(
    file_path='example.pdf',
    lang='ch', 
    use_gpu=True,
    gpu_params=config.pdf_ocr_params
)
docs = processor.process()

# æ‰‹åŠ¨é…ç½®GPUå‚æ•°
processor = PDFProcessor(file_path='example.pdf', lang='ch', use_gpu=True)
processor.configure_gpu(
    batch_size=4,              # æ‰¹å¤„ç†å¤§å°
    min_pages_for_batch=3,     # æœ€å°å¯ç”¨æ‰¹å¤„ç†çš„é¡µæ•°
    det_limit_side_len=1280,   # æ£€æµ‹åˆ†è¾¨ç‡ï¼ˆæ›´é«˜åˆ†è¾¨ç‡å¯èƒ½æé«˜å‡†ç¡®æ€§ä½†é™ä½é€Ÿåº¦ï¼‰
    rec_batch_num=15,          # è¯†åˆ«æ‰¹å¤„ç†é‡
    det_batch_num=8,           # æ£€æµ‹æ‰¹å¤„ç†é‡
    use_tensorrt=True          # ä½¿ç”¨TensorRTåŠ é€Ÿï¼ˆéœ€è¦å®‰è£…TensorRTï¼‰
)
docs = processor.process()

# ä½¿ç”¨å¤§æ–‡æ¡£ä¼˜åŒ–å‚æ•°
processor = PDFProcessor(
    file_path='large_document.pdf',
    lang='ch', 
    use_gpu=True,
    gpu_params=config.pdf_ocr_large_doc_params
)
docs = processor.process()

# ä½¿ç”¨1050Tiä¼˜åŒ–å‚æ•°
processor = PDFProcessor(
    file_path='example.pdf',
    lang='ch', 
    use_gpu=True,
    gpu_params=config.pdf_ocr_1050ti_params
)
docs = processor.process()

# ä¸ä½¿ç”¨GPU
processor = PDFProcessor(file_path='example.pdf', lang='ch', use_gpu=False)
docs = processor.process()
"""

# ä½¿ç”¨å½©è‰²æ—¥å¿—æ ¼å¼å’Œæ›´ç®€æ´çš„è¾“å‡º
class ColoredFormatter(logging.Formatter):
    """è‡ªå®šä¹‰å½©è‰²æ—¥å¿—æ ¼å¼å™¨"""
    COLORS = {
        'INFO': '\033[92m',      # ç»¿è‰²
        'WARNING': '\033[93m',   # é»„è‰²
        'ERROR': '\033[91m',     # çº¢è‰²
        'CRITICAL': '\033[91m',  # çº¢è‰²
        'DEBUG': '\033[94m',     # è“è‰²
        'RESET': '\033[0m'       # é‡ç½®é¢œè‰²
    }
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        reset_color = self.COLORS['RESET']
        
        # ç®€åŒ–æ—¶é—´æ ¼å¼ï¼Œåªæ˜¾ç¤ºæ—¶:åˆ†:ç§’
        record.asctime = self.formatTime(record, datefmt='%H:%M:%S')
        
        # ä½¿ç”¨å›¾æ ‡ä»£æ›¿æ—¥å¿—çº§åˆ«ï¼Œå¢å¼ºå¯è¯»æ€§
        if record.levelname == 'INFO':
            level_icon = 'â„¹ï¸'
        elif record.levelname == 'WARNING':
            level_icon = 'âš ï¸'
        elif record.levelname == 'ERROR':
            level_icon = 'âŒ'
        elif record.levelname == 'CRITICAL':
            level_icon = 'ğŸ”¥'
        else:
            level_icon = 'ğŸ”'
            
        # æ›¿æ¢åŸå§‹æ¶ˆæ¯ä¸­çš„å¤šä½™æ ‡ç­¾
        message = record.getMessage()
        message = message.replace('[æ–‡æ¡£åŠ è½½]', 'ğŸ“„').replace('[PDFè½¬æ¢]', 'ğŸ”„')
        message = message.replace('[PDFå¤„ç†]', 'ğŸ“Š').replace('[OCRå¤„ç†]', 'ğŸ‘ï¸')
        
        # ç»„è£…æœ€ç»ˆæ—¥å¿—æ ¼å¼
        log_fmt = f"{log_color}{record.asctime} {level_icon} {message}{reset_color}"
        record.msg = log_fmt
        return super(logging.Formatter, self).format(record)

# æ›´æ–°æ—¥å¿—é…ç½®ï¼Œæ›¿æ¢build_vector_store.pyä¸­çš„ç›¸åº”ä»£ç 
def setup_logging():
    handler = logging.StreamHandler(stream=sys.stdout)
    handler.setFormatter(ColoredFormatter())
    
    # è·å–æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.handlers = []  # æ¸…é™¤ç°æœ‰å¤„ç†ç¨‹åº
    root_logger.addHandler(handler)
    root_logger.setLevel(logging.INFO)
    
    # è®¾ç½®ä¸€äº›ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«æ›´é«˜ï¼Œå‡å°‘å¹²æ‰°
    logging.getLogger('paddleocr').setLevel(logging.WARNING)
    logging.getLogger('paddle').setLevel(logging.WARNING)

class PDFProcessor:
    def __init__(self, file_path: str = None, lang: str = 'ch', use_gpu: bool = True, gpu_params: dict = None):
        self.file_path = file_path
        self.lang = lang
        self.use_gpu = use_gpu
        self.base_zoom = 1.2
        self._ocr_engine = None
        
        # GPUç›¸å…³å‚æ•° - é»˜è®¤å€¼
        self.gpu_params = {
            'batch_size': 3,          # æ‰¹å¤„ç†å¤§å°
            'min_pages_for_batch': 3, # å¯ç”¨æ‰¹å¤„ç†çš„æœ€å°é¡µæ•°
            'det_limit_side_len': 960,# æ£€æµ‹åˆ†è¾¨ç‡
            'rec_batch_num': 8,       # è¯†åˆ«æ‰¹å¤„ç†é‡
            'det_batch_num': 4,       # æ£€æµ‹æ‰¹å¤„ç†é‡
            'use_tensorrt': False     # æ˜¯å¦ä½¿ç”¨TensorRTåŠ é€Ÿ
        }
        
        # å¦‚æœæä¾›äº†GPUå‚æ•°ï¼Œåˆ™ä½¿ç”¨æä¾›çš„å‚æ•°
        if gpu_params is not None:
            for key, value in gpu_params.items():
                if key in self.gpu_params:
                    self.gpu_params[key] = value
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        self.gpu_available = False
        self._check_gpu_availability()
        
    def _check_gpu_availability(self):
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        try:
            # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡
            if 'CUDA_VISIBLE_DEVICES' not in os.environ:
                os.environ['CUDA_VISIBLE_DEVICES'] = '0'
                
            # å°è¯•ä½¿ç”¨torchæ£€æµ‹CUDAå¯ç”¨æ€§
            cuda_available = torch.cuda.is_available()
            if cuda_available:
                gpu_name = torch.cuda.get_device_name(0)
                gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
                self.gpu_available = True
                logging.info(f"âœ… GPUå¯ç”¨: {gpu_name}, æ˜¾å­˜: {gpu_mem:.1f}GB")
                
                # é’ˆå¯¹1050Tiç‰¹åˆ«ä¼˜åŒ–å‚æ•°
                if "1050 Ti" in gpu_name:
                    logging.info(f"âš¡ æ£€æµ‹åˆ°1050Ti GPUï¼Œåº”ç”¨ä¼˜åŒ–å‚æ•°")
                    # 1050Tiæœ‰4GBæ˜¾å­˜ï¼Œé’ˆå¯¹æ€§è®¾ç½®å‚æ•°
                    self.gpu_params = {
                        'batch_size': 2,          # è¾ƒå°æ‰¹å¤„ç†å¤§å°é¿å…æ˜¾å­˜æº¢å‡º
                        'min_pages_for_batch': 2, # æ›´ä½çš„æ‰¹å¤„ç†å¯ç”¨é˜ˆå€¼
                        'det_limit_side_len': 640,# é™ä½æ£€æµ‹åˆ†è¾¨ç‡ä»¥å‡å°‘æ˜¾å­˜å ç”¨
                        'rec_batch_num': 4,       # è¾ƒå°è¯†åˆ«æ‰¹å¤„ç†é‡
                        'det_batch_num': 2,       # è¾ƒå°æ£€æµ‹æ‰¹å¤„ç†é‡
                        'use_tensorrt': False     # 1050Tié€šå¸¸ä¸æ”¯æŒé«˜ç‰ˆæœ¬TensorRT
                    }
            else:
                logging.warning("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
                self.gpu_available = False
                self.use_gpu = False
                
            # è®¾ç½®paddleç¯å¢ƒï¼ˆæ— è®ºæ˜¯å¦æœ‰GPUï¼‰
            try:
                if self.use_gpu and self.gpu_available:
                    paddle.set_device('gpu:0')
                    logging.info("âœ… Paddleå·²è®¾ç½®ä¸ºGPUæ¨¡å¼")
                else:
                    paddle.set_device('cpu')
                    logging.info("âœ… Paddleå·²è®¾ç½®ä¸ºCPUæ¨¡å¼")
            except Exception as e:
                logging.warning(f"âš ï¸ Paddleè®¾å¤‡è®¾ç½®å¤±è´¥: {str(e)}")
                if self.use_gpu:
                    self.use_gpu = False
                    logging.warning("âš ï¸ å·²è‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
                
        except Exception as e:
            logging.error(f"âš ï¸ GPUæ£€æµ‹å¤±è´¥: {str(e)}")
            self.gpu_available = False
            self.use_gpu = False

    def configure_gpu(self, **kwargs):
        """é…ç½®GPUç›¸å…³å‚æ•°
        
        å‚æ•°:
            batch_size (int): æ‰¹å¤„ç†å¤§å°
            min_pages_for_batch (int): å¯ç”¨æ‰¹å¤„ç†çš„æœ€å°é¡µæ•°
            det_limit_side_len (int): æ£€æµ‹åˆ†è¾¨ç‡
            rec_batch_num (int): è¯†åˆ«æ‰¹å¤„ç†é‡
            det_batch_num (int): æ£€æµ‹æ‰¹å¤„ç†é‡
            use_tensorrt (bool): æ˜¯å¦ä½¿ç”¨TensorRTåŠ é€Ÿ
        """
        # æ›´æ–°GPUå‚æ•°
        for key, value in kwargs.items():
            if key in self.gpu_params:
                self.gpu_params[key] = value
                logging.info(f"æ›´æ–°GPUå‚æ•°: {key} = {value}")
        
        # å¦‚æœå·²ç»åˆå§‹åŒ–äº†OCRå¼•æ“ï¼Œåˆ™éœ€è¦é‡æ–°åˆå§‹åŒ–
        if self._ocr_engine is not None:
            logging.info("å‚æ•°å·²æ›´æ”¹ï¼Œé‡æ–°åˆå§‹åŒ–OCRå¼•æ“...")
            self._ocr_engine = None

    @property
    def ocr_engine(self):
        if self._ocr_engine is None:
            # æ ¹æ®å®é™…GPUå¯ç”¨æ€§è®¾ç½®use_gpu
            actual_use_gpu = self.use_gpu and self.gpu_available
            
            try:
                # åˆå§‹åŒ–OCRå¼•æ“
                self._ocr_engine = PaddleOCR(
                    use_angle_cls=False,
                    lang=self.lang,
                    use_gpu=actual_use_gpu,  # ä½¿ç”¨å®é™…GPUå¯ç”¨æ€§
                    show_log=False,  # å‡å°‘æ—¥å¿—è¾“å‡º
                    rec_image_shape="3, 48, 320",
                    drop_score=0.6,
                    det_limit_side_len=self.gpu_params['det_limit_side_len'],  # æ£€æµ‹åˆ†è¾¨ç‡
                    det_db_unclip_ratio=1.5,  # ä¼˜åŒ–æ£€æµ‹å‚æ•°
                    rec_algorithm='SVTR_LCNet',
                    rec_batch_num=self.gpu_params['rec_batch_num'],  # è¯†åˆ«æ‰¹å¤„ç†é‡
                    det_batch_num=self.gpu_params['det_batch_num'],  # æ£€æµ‹æ‰¹å¤„ç†é‡
                    use_tensorrt=self.gpu_params['use_tensorrt']  # TensorRTåŠ é€Ÿ
                )
                
                # æ—¥å¿—è¾“å‡ºOCRå¼•æ“é…ç½®æƒ…å†µ
                mode_str = "GPU" if actual_use_gpu else "CPU"
                logging.info(f"ğŸ”§ OCRå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨{mode_str}æ¨¡å¼")
            except Exception as e:
                logging.error(f"âŒ OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                logging.info("âš ï¸ å°è¯•ä½¿ç”¨CPUæ¨¡å¼åˆå§‹åŒ–OCRå¼•æ“")
                try:
                    # ç¡®ä¿ä½¿ç”¨CPUè®¾å¤‡
                    paddle.set_device('cpu')
                    self._ocr_engine = PaddleOCR(
                        use_angle_cls=False,
                        lang=self.lang,
                        use_gpu=False,  # å¼ºåˆ¶ä½¿ç”¨CPU
                        show_log=False
                    )
                    logging.info("ğŸ”§ OCRå¼•æ“(CPUæ¨¡å¼)åˆå§‹åŒ–å®Œæˆ")
                except Exception as e2:
                    logging.error(f"âŒ CPUæ¨¡å¼åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {str(e2)}")
                    raise e2
            
        return self._ocr_engine

    def _convert_pages(self, pdf_path: str) -> List[Tuple[int, np.ndarray]]:
        try:
            with fitz.open(pdf_path) as doc:
                page_count = doc.page_count
                logging.info(f"[PDFå¤„ç†] å¼€å§‹è½¬æ¢ '{Path(pdf_path).name}' ({page_count}é¡µ)")
                
                # ç›´æ¥å¤„ç†æ¯ä¸€é¡µï¼Œä¸ä½¿ç”¨è¿›ç¨‹æ± 
                converted = []
                for pg in range(page_count):
                    try:
                        page = doc[pg]
                        matrix = fitz.Matrix(self.base_zoom, self.base_zoom)
                        pix = page.get_pixmap(matrix=matrix, alpha=False)
                        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)
                        converted.append((pg, img_array))
                    except Exception as e:
                        logging.warning(f"[PDFè½¬æ¢] é¡µé¢{pg+1}å¤±è´¥: {str(e)}")
                
                if not converted:
                    logging.error("[PDFè½¬æ¢] å¤±è´¥: æ²¡æœ‰é¡µé¢æˆåŠŸè½¬æ¢")
                else:
                    logging.info(f"[PDFè½¬æ¢] å®Œæˆ: æˆåŠŸè½¬æ¢{len(converted)}/{page_count}é¡µ ({int(len(converted)/page_count*100)}%)")
                
                # ç¡®ä¿é¡µç é¡ºåºæ­£ç¡®
                converted.sort(key=lambda x: x[0])
                return converted
                
        except Exception as e:
            logging.error(f"[PDFè½¬æ¢] å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _convert_page(args: tuple) -> Optional[Tuple[int, np.ndarray]]:
        """
        æ­¤æ–¹æ³•ä¿ç•™ä½†ä¸å†ä½¿ç”¨ï¼Œä¸ºä¿æŒAPIå…¼å®¹æ€§
        """
        pdf_path, pg, zoom = args
        try:
            with fitz.open(pdf_path) as doc:
                page = doc[pg]
                matrix = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=matrix, alpha=False)
                img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)
                return (pg, img_array)  # ç›´æ¥è¿”å›RGBæ ¼å¼
        except Exception as e:
            logging.warning(f"Page {pg} conversion failed: {e}")
            return None

    def _parse_ocr_result(self, result: list) -> str:
        return "\n".join(
            line[1][0].strip() for line in result[0]
            if line[1][0].strip()
        ) if result and result[0] else ""

    def _print_progress_bar(self, progress: float, current_page: int):
        """æ§åˆ¶å°è¿›åº¦æ¡æ˜¾ç¤ºï¼Œæ”¹ä¸ºå•è¡Œå›ºå®šæ ¼å¼"""
        bar_length = 20
        filled = int(progress / 100 * bar_length)
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        # ä½¿ç”¨\rç¡®ä¿æ¯ä¸ªæ–‡ä»¶åªå ç”¨ä¸€è¡Œ
        print(f"\r[OCRè¯†åˆ«] è¿›åº¦: {bar} {progress:.1f}% | é¡µé¢: {current_page}", end='', flush=True)

    def _print_summary(self, total: int, success: int, failed: list, duration: float):
        """è¾“å‡ºå¤„ç†ç»“æœæ‘˜è¦"""
        print("\n" + "â”€" * 40)
        logging.info(f"[OCRå¤„ç†] æ‘˜è¦:")
        logging.info(f"  â€¢ æ€»é¡µæ•°    : {total} é¡µ")
        logging.info(f"  â€¢ æˆåŠŸè¯†åˆ«  : {success} é¡µ ({success / total * 100:.1f}%)")
        if failed:
            logging.info(f"  â€¢ å¤±è´¥é¡µé¢  : {len(failed)} é¡µ ({', '.join(map(str, failed[:5]))}" + 
                         (f"...ç­‰{len(failed)-5}é¡µ" if len(failed) > 5 else "") + ")")
        logging.info(f"  â€¢ æ€»è€—æ—¶    : {duration:.1f} ç§’")
        logging.info(f"  â€¢ å¹³å‡é€Ÿåº¦  : {duration / total:.1f} ç§’/é¡µ" if total > 0 else "")
        print("â”€" * 40 + "\n")

    def _batch_process_pages(self, converted_pages: List[Tuple[int, np.ndarray]]) -> List[Document]:
        """ä½¿ç”¨æ‰¹å¤„ç†æ–¹å¼å¤„ç†é¡µé¢ï¼Œæé«˜GPUåˆ©ç”¨ç‡"""
        documents = []
        batch_size = self.gpu_params['batch_size']
        total_pages = len(converted_pages)
        success_count = 0
        fail_pages = []
        stage_start = time.time()
        
        logging.info(f"[OCRå¤„ç†] ä½¿ç”¨GPUæ‰¹å¤„ç†æ¨¡å¼ (æ‰¹æ¬¡å¤§å°: {batch_size})")
        
        # ç¡®ä¿GPUæ¨¡å¼æ¿€æ´»
        if not (self.use_gpu and self.gpu_available):
            logging.warning("[OCRå¤„ç†] GPUä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°å•é¡µå¤„ç†æ¨¡å¼")
            # å•é¡µå¤„ç†æ¨¡å¼
            return self.process_pdf_single_page(converted_pages)
        
        # é¦–å…ˆæ¸…ç†GPUç¼“å­˜
        try:
            torch.cuda.empty_cache()
        except:
            pass
            
        # åˆ†æ‰¹å¤„ç†
        for batch_idx in range(0, total_pages, batch_size):
            batch_end = min(batch_idx + batch_size, total_pages)
            batch_pages = converted_pages[batch_idx:batch_end]
            
            
            # æ‰¹é‡å¤„ç†å‰é‡Šæ”¾å†…å­˜
            if self.gpu_available and batch_idx > 0:
                # ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
                try:
                    import gc
                    gc.collect()
                    torch.cuda.empty_cache()
                except:
                    pass
            
            # æ‰¹é‡å¤„ç†
            batch_start = time.time()
            
            for pg, img in batch_pages:
                page_num = pg + 1
                try:
                    # å¤„ç†å‰è°ƒæ•´å›¾åƒå¤§å°ä»¥èŠ‚çœæ˜¾å­˜
                    if max(img.shape[0], img.shape[1]) > 1600:
                        scale = 1600 / max(img.shape[0], img.shape[1])
                        new_h, new_w = int(img.shape[0] * scale), int(img.shape[1] * scale)
                        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
                        
                    # OCRå¤„ç†
                    result = self.ocr_engine.ocr(img, cls=False)
                    page_text = self._parse_ocr_result(result)
                    
                    # è®°å½•æ–‡æ¡£
                    documents.append(
                        Document(
                            page_content=page_text,
                            metadata={
                                "page": page_num,
                                "image_size": img.shape,
                                "batch_process": True
                            }
                        )
                    )
                    success_count += 1
                except Exception as e:
                    fail_pages.append(page_num)
                    logging.warning(f"[OCRå¤„ç†] é¡µé¢{page_num}å¤±è´¥: {str(e)}")
            
            
            # æ¯æ‰¹æ¬¡åæ¸…ç†GPUå†…å­˜
            if self.gpu_available:
                try:
                    import gc
                    gc.collect()
                    torch.cuda.empty_cache()
                except:
                    pass
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - stage_start
        # æ¸…ç©ºè¿›åº¦æ¡
        print()
        self._print_summary(total_pages, success_count, fail_pages, total_time)
        
        # æŒ‰é¡µç æ’åºè¿”å›
        documents.sort(key=lambda doc: doc.metadata["page"])
        return documents
        
    def process_pdf_single_page(self, converted_pages: List[Tuple[int, np.ndarray]]) -> List[Document]:
        """ä½¿ç”¨å•é¡µå¤„ç†æ¨¡å¼å¤„ç†PDF"""
        documents = []
        total_pages = len(converted_pages)
        success_count = 0
        fail_pages = []
        stage_start = time.time()
        
        logging.info("[OCRå¤„ç†] ä½¿ç”¨å•é¡µå¤„ç†æ¨¡å¼")
        
        # å­˜å‚¨ä¸Šæ¬¡è¿›åº¦æ›´æ–°çš„æ—¶é—´ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
        last_log_time = time.time()
        
        for idx, (pg, img) in enumerate(converted_pages):
            page_num = pg + 1
            page_start = time.time()

            try:                   
                # å¤„ç†å‰è°ƒæ•´å›¾åƒå¤§å°ä»¥èŠ‚çœæ˜¾å­˜
                if max(img.shape[0], img.shape[1]) > 1600:
                    scale = 1600 / max(img.shape[0], img.shape[1])
                    new_h, new_w = int(img.shape[0] * scale), int(img.shape[1] * scale)
                    img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)

                # OCRå¤„ç†
                result = self.ocr_engine.ocr(img, cls=False)
                page_text = self._parse_ocr_result(result)

                # è®°å½•æ–‡æ¡£
                documents.append(
                    Document(
                        page_content=page_text,
                        metadata={
                            "page": page_num,
                            "image_size": img.shape,
                            "process_time": time.time() - page_start
                        }
                    )
                )
                success_count += 1
            except Exception as e:
                fail_pages.append(page_num)
                logging.warning(f"[OCRå¤„ç†] é¡µé¢{page_num}å¤±è´¥: {str(e)}")

        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - stage_start
        # æ¸…ç©ºè¿›åº¦æ¡
        print()
        self._print_summary(total_pages, success_count, fail_pages, total_time)
        return documents
        
    def process_pdf(self, pdf_path: str) -> List[Document]:
        """å¤„ç†PDFå¹¶æ˜¾ç¤ºå®æ—¶è¿›åº¦"""
        documents = []
        stage_start = time.time()

        try:            
            # é˜¶æ®µ1ï¼šPDFè½¬å›¾åƒ
            logging.info("[PDFå¤„ç†] é˜¶æ®µ1/2: é¡µé¢è½¬æ¢ä¸­...")
            converted_pages = self._convert_pages(pdf_path)
            if not converted_pages:
                logging.warning("[PDFå¤„ç†] æ²¡æœ‰å¯å¤„ç†é¡µé¢")
                return []

            total_pages = len(converted_pages)
            parse_time = time.time() - stage_start
            logging.info(f"[PDFå¤„ç†] é¡µé¢è½¬æ¢å®Œæˆï¼Œå…±{total_pages}é¡µ (è€—æ—¶{parse_time:.1f}s)")

            # é˜¶æ®µ2ï¼šOCRå¤„ç†
            logging.info("[PDFå¤„ç†] é˜¶æ®µ2/2: OCRæ–‡å­—è¯†åˆ«ä¸­...")

            # GPUæ¨¡å¼ä¸‹ä½¿ç”¨æ‰¹å¤„ç†æé«˜æ€§èƒ½
            if self.use_gpu and self.gpu_available and total_pages > self.gpu_params['min_pages_for_batch']:
                return self._batch_process_pages(converted_pages)
            else:
                # å•é¡µå¤„ç†æ¨¡å¼
                return self.process_pdf_single_page(converted_pages)

        except Exception as e:
            logging.error(f"[PDFå¤„ç†] å¤„ç†å¼‚å¸¸ç»ˆæ­¢: {str(e)}")
            return []

    def process(self) -> List[Document]:
        """å¤„ç†PDFæ–‡ä»¶ï¼Œè¿”å›æ–‡æ¡£å¯¹è±¡åˆ—è¡¨"""
        if not self.file_path:
            raise ValueError("è¯·æä¾›PDFæ–‡ä»¶è·¯å¾„")
        return self.process_pdf(self.file_path)

    def _generate_processing_report(self):
        """ç”Ÿæˆæ–‡æ¡£å¤„ç†æŠ¥å‘Šï¼Œæä¾›æ›´ä¸°å¯Œçš„ç»Ÿè®¡ä¿¡æ¯"""
        report = {
            "æ€»æ–‡ä»¶æ•°": len(self.processed_files),
            "æ€»é¡µæ•°": sum(info.get("pages", 0) for info in self.processed_files.values()),
            "å¹³å‡æ¯æ–‡ä»¶é¡µæ•°": sum(info.get("pages", 0) for info in self.processed_files.values()) / max(len(self.processed_files), 1),
            "å¤„ç†å¤±è´¥æ–‡ä»¶æ•°": self.failed_files_count,
            "æˆåŠŸç‡": 1 - (self.failed_files_count / max(len(self.processed_files), 1)),
            "æ–‡ä»¶ç±»å‹ç»Ÿè®¡": {},
            "å¤„ç†æ—¶é—´": datetime.now().isoformat()
        }
        
        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        for file_path in self.processed_files:
            ext = Path(file_path).suffix.lower()
            if ext in report["æ–‡ä»¶ç±»å‹ç»Ÿè®¡"]:
                report["æ–‡ä»¶ç±»å‹ç»Ÿè®¡"][ext] += 1
            else:
                report["æ–‡ä»¶ç±»å‹ç»Ÿè®¡"][ext] = 1
        
        # ä¿å­˜æŠ¥å‘Š
        with open(self.cache_dir / "processing_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # è¾“å‡ºç®€è¦æŠ¥å‘Š
        logger.info("\nğŸ“Š æ–‡æ¡£å¤„ç†æŠ¥å‘Š")
        logger.info(f"ğŸ“‘ æ€»æ–‡ä»¶æ•°: {report['æ€»æ–‡ä»¶æ•°']} ä¸ª")
        logger.info(f"ğŸ“„ æ€»é¡µæ•°: {report['æ€»é¡µæ•°']} é¡µ")
        logger.info(f"ğŸ“Š å¹³å‡æ¯æ–‡ä»¶: {report['å¹³å‡æ¯æ–‡ä»¶é¡µæ•°']:.1f} é¡µ")
        logger.info(f"âœ… æˆåŠŸç‡: {report['æˆåŠŸç‡']:.1%}")
        
        # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        logger.info("ğŸ“‚ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for ext, count in report["æ–‡ä»¶ç±»å‹ç»Ÿè®¡"].items():
            logger.info(f"   - {ext}: {count} ä¸ª")